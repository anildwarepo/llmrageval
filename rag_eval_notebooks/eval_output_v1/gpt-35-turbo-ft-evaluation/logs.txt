2024-02-26 17:49:59 -0800   12436 execution.bulk     INFO     Current system's available memory is 18857.734375MB, memory consumption of current process is 177.9765625MB, estimated available worker count is 18857.734375/177.9765625 = 105
2024-02-26 17:49:59 -0800   12436 execution.bulk     INFO     Set process count to 4 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 45, 'estimated_worker_count_based_on_memory_usage': 105}.
2024-02-26 17:50:04 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(1) start execution.
2024-02-26 17:50:04 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(2) start execution.
2024-02-26 17:50:04 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(3) start execution.
2024-02-26 17:50:04 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(4) start execution.
2024-02-26 17:51:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 17:51:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 0] [Processing: 4] [Pending: 41]
2024-02-26 17:51:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 1 (Process name(SpawnProcess-2)-Process id(26672)-Line number(1)), line 2 (Process name(SpawnProcess-3)-Process id(11968)-Line number(2)), line 3 (Process name(SpawnProcess-4)-Process id(21216)-Line number(3)), line 4 (Process name(SpawnProcess-5)-Process id(13092)-Line number(4)).
2024-02-26 17:51:20 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(4) completed.
2024-02-26 17:51:20 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(5) start execution.
2024-02-26 17:51:23 -0800   21216 execution          WARNING  gpt_retrieval_score in line 3 has been running for 60 seconds, stacktrace of thread 15392:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 17:51:27 -0800   26672 execution          WARNING  gpt_retrieval_score in line 1 has been running for 60 seconds, stacktrace of thread 15484:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 17:51:56 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(2) completed.
2024-02-26 17:51:56 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(6) start execution.
2024-02-26 17:52:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 17:52:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 2] [Processing: 4] [Pending: 39]
2024-02-26 17:52:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 1 (Process name(SpawnProcess-2)-Process id(26672)-Line number(1)), line 3 (Process name(SpawnProcess-4)-Process id(21216)-Line number(3)), line 5 (Process name(SpawnProcess-5)-Process id(13092)-Line number(5)), line 6 (Process name(SpawnProcess-3)-Process id(11968)-Line number(6)).
2024-02-26 17:52:30 -0800   13092 execution          WARNING  gpt_retrieval_score in line 5 has been running for 60 seconds, stacktrace of thread 30900:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 17:52:44 -0800   26672 execution          WARNING  gpt_relevance in line 1 has been running for 60 seconds, stacktrace of thread 15484:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 17:52:45 -0800   21216 execution          WARNING  gpt_relevance in line 3 has been running for 60 seconds, stacktrace of thread 15392:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 17:52:47 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(3) completed.
2024-02-26 17:52:47 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(7) start execution.
2024-02-26 17:52:49 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(1) completed.
2024-02-26 17:52:49 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(8) start execution.
2024-02-26 17:52:50 -0800   12436 execution.bulk     INFO     Finished 4 / 45 lines.
2024-02-26 17:52:50 -0800   12436 execution.bulk     INFO     Average execution time for completed lines: 41.57 seconds. Estimated time for incomplete lines: 1704.37 seconds.
2024-02-26 17:53:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 17:53:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 4] [Processing: 4] [Pending: 37]
2024-02-26 17:53:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 5 (Process name(SpawnProcess-5)-Process id(13092)-Line number(5)), line 6 (Process name(SpawnProcess-3)-Process id(11968)-Line number(6)), line 7 (Process name(SpawnProcess-4)-Process id(21216)-Line number(7)), line 8 (Process name(SpawnProcess-2)-Process id(26672)-Line number(8)).
2024-02-26 17:53:32 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(5) completed.
2024-02-26 17:53:32 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(9) start execution.
2024-02-26 17:53:36 -0800   11968 execution          WARNING  gpt_retrieval_score in line 6 has been running for 60 seconds, stacktrace of thread 30872:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 17:54:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 17:54:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 5] [Processing: 4] [Pending: 36]
2024-02-26 17:54:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 6 (Process name(SpawnProcess-3)-Process id(11968)-Line number(6)), line 7 (Process name(SpawnProcess-4)-Process id(21216)-Line number(7)), line 8 (Process name(SpawnProcess-2)-Process id(26672)-Line number(8)), line 9 (Process name(SpawnProcess-5)-Process id(13092)-Line number(9)).
2024-02-26 17:54:25 -0800   26672 execution          WARNING  gpt_retrieval_score in line 8 has been running for 60 seconds, stacktrace of thread 7876:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 17:54:37 -0800   11968 execution          WARNING  gpt_relevance in line 6 has been running for 60 seconds, stacktrace of thread 30872:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 17:54:51 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(7) completed.
2024-02-26 17:54:51 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(10) start execution.
2024-02-26 17:54:56 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(8) completed.
2024-02-26 17:54:56 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(11) start execution.
2024-02-26 17:55:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 17:55:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 7] [Processing: 4] [Pending: 34]
2024-02-26 17:55:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 6 (Process name(SpawnProcess-3)-Process id(11968)-Line number(6)), line 9 (Process name(SpawnProcess-5)-Process id(13092)-Line number(9)), line 10 (Process name(SpawnProcess-4)-Process id(21216)-Line number(10)), line 11 (Process name(SpawnProcess-2)-Process id(26672)-Line number(11)).
2024-02-26 17:55:14 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(6) completed.
2024-02-26 17:55:14 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(12) start execution.
2024-02-26 17:55:15 -0800   12436 execution.bulk     INFO     Finished 8 / 45 lines.
2024-02-26 17:55:15 -0800   12436 execution.bulk     INFO     Average execution time for completed lines: 38.8 seconds. Estimated time for incomplete lines: 1435.6 seconds.
2024-02-26 17:56:00 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(9) completed.
2024-02-26 17:56:00 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(13) start execution.
2024-02-26 17:56:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 17:56:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 9] [Processing: 4] [Pending: 32]
2024-02-26 17:56:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 10 (Process name(SpawnProcess-4)-Process id(21216)-Line number(10)), line 11 (Process name(SpawnProcess-2)-Process id(26672)-Line number(11)), line 12 (Process name(SpawnProcess-3)-Process id(11968)-Line number(12)), line 13 (Process name(SpawnProcess-5)-Process id(13092)-Line number(13)).
2024-02-26 17:56:35 -0800   26672 execution          WARNING  gpt_retrieval_score in line 11 has been running for 60 seconds, stacktrace of thread 9740:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 17:56:53 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(10) completed.
2024-02-26 17:56:53 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(14) start execution.
2024-02-26 17:57:02 -0800   11968 execution          WARNING  gpt_relevance in line 12 has been running for 60 seconds, stacktrace of thread 25744:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 17:57:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 17:57:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 10] [Processing: 4] [Pending: 31]
2024-02-26 17:57:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 11 (Process name(SpawnProcess-2)-Process id(26672)-Line number(11)), line 12 (Process name(SpawnProcess-3)-Process id(11968)-Line number(12)), line 13 (Process name(SpawnProcess-5)-Process id(13092)-Line number(13)), line 14 (Process name(SpawnProcess-4)-Process id(21216)-Line number(14)).
2024-02-26 17:57:25 -0800   13092 execution          WARNING  gpt_retrieval_score in line 13 has been running for 60 seconds, stacktrace of thread 30116:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 17:57:28 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(12) completed.
2024-02-26 17:57:28 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(15) start execution.
2024-02-26 17:57:50 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(11) completed.
2024-02-26 17:57:50 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(16) start execution.
2024-02-26 17:57:51 -0800   12436 execution.bulk     INFO     Finished 12 / 45 lines.
2024-02-26 17:57:51 -0800   12436 execution.bulk     INFO     Average execution time for completed lines: 38.88 seconds. Estimated time for incomplete lines: 1283.04 seconds.
2024-02-26 17:58:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 17:58:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 12] [Processing: 4] [Pending: 29]
2024-02-26 17:58:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 13 (Process name(SpawnProcess-5)-Process id(13092)-Line number(13)), line 14 (Process name(SpawnProcess-4)-Process id(21216)-Line number(14)), line 15 (Process name(SpawnProcess-3)-Process id(11968)-Line number(15)), line 16 (Process name(SpawnProcess-2)-Process id(26672)-Line number(16)).
2024-02-26 17:58:42 -0800   13092 execution          WARNING  gpt_relevance in line 13 has been running for 60 seconds, stacktrace of thread 30116:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 17:58:54 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(15) completed.
2024-02-26 17:58:54 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(17) start execution.
2024-02-26 17:58:54 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(13) completed.
2024-02-26 17:58:54 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(18) start execution.
2024-02-26 17:59:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 17:59:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 14] [Processing: 4] [Pending: 27]
2024-02-26 17:59:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 14 (Process name(SpawnProcess-4)-Process id(21216)-Line number(14)), line 16 (Process name(SpawnProcess-2)-Process id(26672)-Line number(16)), line 17 (Process name(SpawnProcess-3)-Process id(11968)-Line number(17)), line 18 (Process name(SpawnProcess-5)-Process id(13092)-Line number(18)).
2024-02-26 17:59:16 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(14) completed.
2024-02-26 17:59:16 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(19) start execution.
2024-02-26 17:59:54 -0800   11968 execution          WARNING  gpt_groundedness in line 17 has been running for 60 seconds, stacktrace of thread 16696:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:00:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:00:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 15] [Processing: 4] [Pending: 26]
2024-02-26 18:00:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 16 (Process name(SpawnProcess-2)-Process id(26672)-Line number(16)), line 17 (Process name(SpawnProcess-3)-Process id(11968)-Line number(17)), line 18 (Process name(SpawnProcess-5)-Process id(13092)-Line number(18)), line 19 (Process name(SpawnProcess-4)-Process id(21216)-Line number(19)).
2024-02-26 18:00:16 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(16) completed.
2024-02-26 18:00:16 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(20) start execution.
2024-02-26 18:00:17 -0800   12436 execution.bulk     INFO     Finished 16 / 45 lines.
2024-02-26 18:00:17 -0800   12436 execution.bulk     INFO     Average execution time for completed lines: 38.29 seconds. Estimated time for incomplete lines: 1110.41 seconds.
2024-02-26 18:00:24 -0800   13092 execution          WARNING  gpt_retrieval_score in line 18 has been running for 60 seconds, stacktrace of thread 11952:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:00:27 -0800   21216 execution          WARNING  gpt_retrieval_score in line 19 has been running for 60 seconds, stacktrace of thread 14968:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:00:54 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(18) completed.
2024-02-26 18:00:54 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(21) start execution.
2024-02-26 18:00:58 -0800   11968 execution          WARNING  gpt_retrieval_score in line 17 has been running for 60 seconds, stacktrace of thread 16696:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:01:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:01:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 17] [Processing: 4] [Pending: 24]
2024-02-26 18:01:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 17 (Process name(SpawnProcess-3)-Process id(11968)-Line number(17)), line 19 (Process name(SpawnProcess-4)-Process id(21216)-Line number(19)), line 20 (Process name(SpawnProcess-2)-Process id(26672)-Line number(20)), line 21 (Process name(SpawnProcess-5)-Process id(13092)-Line number(21)).
2024-02-26 18:01:10 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(19) completed.
2024-02-26 18:01:10 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(22) start execution.
2024-02-26 18:01:42 -0800   26672 execution          WARNING  gpt_retrieval_score in line 20 has been running for 60 seconds, stacktrace of thread 13584:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:02:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:02:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 18] [Processing: 4] [Pending: 23]
2024-02-26 18:02:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 17 (Process name(SpawnProcess-3)-Process id(11968)-Line number(17)), line 20 (Process name(SpawnProcess-2)-Process id(26672)-Line number(20)), line 21 (Process name(SpawnProcess-5)-Process id(13092)-Line number(21)), line 22 (Process name(SpawnProcess-4)-Process id(21216)-Line number(22)).
2024-02-26 18:02:15 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(17) completed.
2024-02-26 18:02:15 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(23) start execution.
2024-02-26 18:02:42 -0800   21216 execution          WARNING  gpt_retrieval_score in line 22 has been running for 60 seconds, stacktrace of thread 31300:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:02:52 -0800   13092 execution          WARNING  gpt_retrieval_score in line 21 has been running for 60 seconds, stacktrace of thread 29064:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:02:58 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(20) completed.
2024-02-26 18:02:58 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(24) start execution.
2024-02-26 18:02:58 -0800   12436 execution.bulk     INFO     Finished 20 / 45 lines.
2024-02-26 18:02:58 -0800   12436 execution.bulk     INFO     Average execution time for completed lines: 38.69 seconds. Estimated time for incomplete lines: 967.25 seconds.
2024-02-26 18:03:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:03:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 20] [Processing: 4] [Pending: 21]
2024-02-26 18:03:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 21 (Process name(SpawnProcess-5)-Process id(13092)-Line number(21)), line 22 (Process name(SpawnProcess-4)-Process id(21216)-Line number(22)), line 23 (Process name(SpawnProcess-3)-Process id(11968)-Line number(23)), line 24 (Process name(SpawnProcess-2)-Process id(26672)-Line number(24)).
2024-02-26 18:03:27 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(22) completed.
2024-02-26 18:03:27 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(25) start execution.
2024-02-26 18:03:28 -0800   11968 execution          WARNING  gpt_retrieval_score in line 23 has been running for 60 seconds, stacktrace of thread 17108:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:03:41 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(21) completed.
2024-02-26 18:03:41 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(26) start execution.
2024-02-26 18:04:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:04:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 22] [Processing: 4] [Pending: 19]
2024-02-26 18:04:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 23 (Process name(SpawnProcess-3)-Process id(11968)-Line number(23)), line 24 (Process name(SpawnProcess-2)-Process id(26672)-Line number(24)), line 25 (Process name(SpawnProcess-4)-Process id(21216)-Line number(25)), line 26 (Process name(SpawnProcess-5)-Process id(13092)-Line number(26)).
2024-02-26 18:04:19 -0800   21216 execution          WARNING  [gpt_retrieval_score in line 25 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:04:19 -0800   21216 execution          WARNING  [gpt_retrieval_score in line 25 (index starts from 0)] stderr> RateLimitError #0, Retry-After=10, Back off 10.0 seconds for retry.
2024-02-26 18:04:30 -0800   26672 execution          WARNING  gpt_retrieval_score in line 24 has been running for 60 seconds, stacktrace of thread 22480:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:04:32 -0800   11968 execution          WARNING  gpt_relevance in line 23 has been running for 60 seconds, stacktrace of thread 17108:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:04:39 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(23) completed.
2024-02-26 18:04:39 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(27) start execution.
2024-02-26 18:04:52 -0800   21216 execution          WARNING  gpt_retrieval_score in line 25 has been running for 60 seconds, stacktrace of thread 13728:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:05:01 -0800   13092 execution          WARNING  gpt_retrieval_score in line 26 has been running for 60 seconds, stacktrace of thread 13540:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:05:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:05:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 23] [Processing: 4] [Pending: 18]
2024-02-26 18:05:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 24 (Process name(SpawnProcess-2)-Process id(26672)-Line number(24)), line 25 (Process name(SpawnProcess-4)-Process id(21216)-Line number(25)), line 26 (Process name(SpawnProcess-5)-Process id(13092)-Line number(26)), line 27 (Process name(SpawnProcess-3)-Process id(11968)-Line number(27)).
2024-02-26 18:05:16 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(24) completed.
2024-02-26 18:05:16 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(28) start execution.
2024-02-26 18:05:17 -0800   12436 execution.bulk     INFO     Finished 24 / 45 lines.
2024-02-26 18:05:17 -0800   12436 execution.bulk     INFO     Average execution time for completed lines: 38.04 seconds. Estimated time for incomplete lines: 798.84 seconds.
2024-02-26 18:05:30 -0800   13092 execution          WARNING  [gpt_relevance in line 26 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:05:30 -0800   13092 execution          WARNING  [gpt_relevance in line 26 (index starts from 0)] stderr> RateLimitError #0, Retry-After=10, Back off 10.0 seconds for retry.
2024-02-26 18:06:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:06:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 24] [Processing: 4] [Pending: 17]
2024-02-26 18:06:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 25 (Process name(SpawnProcess-4)-Process id(21216)-Line number(25)), line 26 (Process name(SpawnProcess-5)-Process id(13092)-Line number(26)), line 27 (Process name(SpawnProcess-3)-Process id(11968)-Line number(27)), line 28 (Process name(SpawnProcess-2)-Process id(26672)-Line number(28)).
2024-02-26 18:06:05 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(27) completed.
2024-02-26 18:06:05 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(29) start execution.
2024-02-26 18:06:16 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(26) completed.
2024-02-26 18:06:16 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(30) start execution.
2024-02-26 18:06:20 -0800   21216 execution          WARNING  [gpt_relevance in line 25 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:06:20 -0800   21216 execution          WARNING  [gpt_relevance in line 25 (index starts from 0)] stderr> RateLimitError #0, Retry-After=7, Back off 7.0 seconds for retry.
2024-02-26 18:06:29 -0800   11968 execution          WARNING  [gpt_groundedness in line 29 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 12 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:06:29 -0800   11968 execution          WARNING  [gpt_groundedness in line 29 (index starts from 0)] stderr> RateLimitError #0, Retry-After=12, Back off 12.0 seconds for retry.
2024-02-26 18:06:32 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(28) completed.
2024-02-26 18:06:32 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(31) start execution.
2024-02-26 18:06:45 -0800   26672 execution          WARNING  [gpt_groundedness in line 31 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 15 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:06:45 -0800   26672 execution          WARNING  [gpt_groundedness in line 31 (index starts from 0)] stderr> RateLimitError #0, Retry-After=15, Back off 15.0 seconds for retry.
2024-02-26 18:06:47 -0800   21216 execution          WARNING  gpt_relevance in line 25 has been running for 60 seconds, stacktrace of thread 13728:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:06:58 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(25) completed.
2024-02-26 18:06:58 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(32) start execution.
2024-02-26 18:06:58 -0800   12436 execution.bulk     INFO     Finished 28 / 45 lines.
2024-02-26 18:06:58 -0800   12436 execution.bulk     INFO     Average execution time for completed lines: 36.2 seconds. Estimated time for incomplete lines: 615.4 seconds.
2024-02-26 18:07:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:07:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 28] [Processing: 4] [Pending: 13]
2024-02-26 18:07:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 29 (Process name(SpawnProcess-3)-Process id(11968)-Line number(29)), line 30 (Process name(SpawnProcess-5)-Process id(13092)-Line number(30)), line 31 (Process name(SpawnProcess-2)-Process id(26672)-Line number(31)), line 32 (Process name(SpawnProcess-4)-Process id(21216)-Line number(32)).
2024-02-26 18:07:28 -0800   21216 execution          WARNING  [gpt_groundedness in line 32 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 13 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:07:28 -0800   21216 execution          WARNING  [gpt_groundedness in line 32 (index starts from 0)] stderr> RateLimitError #0, Retry-After=13, Back off 13.0 seconds for retry.
2024-02-26 18:07:32 -0800   26672 execution          WARNING  gpt_groundedness in line 31 has been running for 60 seconds, stacktrace of thread 17888:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:07:40 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(30) completed.
2024-02-26 18:07:40 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(33) start execution.
2024-02-26 18:07:46 -0800   13092 execution          WARNING  [gpt_groundedness in line 33 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 12 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:07:46 -0800   13092 execution          WARNING  [gpt_groundedness in line 33 (index starts from 0)] stderr> RateLimitError #0, Retry-After=12, Back off 12.0 seconds for retry.
2024-02-26 18:08:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:08:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 29] [Processing: 4] [Pending: 12]
2024-02-26 18:08:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 29 (Process name(SpawnProcess-3)-Process id(11968)-Line number(29)), line 31 (Process name(SpawnProcess-2)-Process id(26672)-Line number(31)), line 32 (Process name(SpawnProcess-4)-Process id(21216)-Line number(32)), line 33 (Process name(SpawnProcess-5)-Process id(13092)-Line number(33)).
2024-02-26 18:08:17 -0800   11968 execution          WARNING  [gpt_relevance in line 29 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 11 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:08:17 -0800   11968 execution          WARNING  [gpt_relevance in line 29 (index starts from 0)] stderr> RateLimitError #0, Retry-After=11, Back off 11.0 seconds for retry.
2024-02-26 18:08:42 -0800   26672 execution          WARNING  [gpt_relevance in line 31 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:08:42 -0800   26672 execution          WARNING  [gpt_relevance in line 31 (index starts from 0)] stderr> RateLimitError #0, Retry-After=4, Back off 4.0 seconds for retry.
2024-02-26 18:08:56 -0800   11968 execution          WARNING  gpt_relevance in line 29 has been running for 60 seconds, stacktrace of thread 29128:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:09:01 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(29) completed.
2024-02-26 18:09:01 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(34) start execution.
2024-02-26 18:09:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:09:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 30] [Processing: 4] [Pending: 11]
2024-02-26 18:09:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 31 (Process name(SpawnProcess-2)-Process id(26672)-Line number(31)), line 32 (Process name(SpawnProcess-4)-Process id(21216)-Line number(32)), line 33 (Process name(SpawnProcess-5)-Process id(13092)-Line number(33)), line 34 (Process name(SpawnProcess-3)-Process id(11968)-Line number(34)).
2024-02-26 18:09:13 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(32) completed.
2024-02-26 18:09:13 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(35) start execution.
2024-02-26 18:09:17 -0800   26672 execution          WARNING  gpt_relevance in line 31 has been running for 60 seconds, stacktrace of thread 17888:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:09:26 -0800   13092 execution          WARNING  gpt_retrieval_score in line 33 has been running for 60 seconds, stacktrace of thread 14408:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:09:32 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(31) completed.
2024-02-26 18:09:32 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(36) start execution.
2024-02-26 18:09:32 -0800   12436 execution.bulk     INFO     Finished 32 / 45 lines.
2024-02-26 18:09:32 -0800   12436 execution.bulk     INFO     Average execution time for completed lines: 36.5 seconds. Estimated time for incomplete lines: 474.5 seconds.
2024-02-26 18:10:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:10:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 32] [Processing: 4] [Pending: 9]
2024-02-26 18:10:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 33 (Process name(SpawnProcess-5)-Process id(13092)-Line number(33)), line 34 (Process name(SpawnProcess-3)-Process id(11968)-Line number(34)), line 35 (Process name(SpawnProcess-4)-Process id(21216)-Line number(35)), line 36 (Process name(SpawnProcess-2)-Process id(26672)-Line number(36)).
2024-02-26 18:10:39 -0800   21216 execution          WARNING  gpt_retrieval_score in line 35 has been running for 60 seconds, stacktrace of thread 30984:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:10:55 -0800   26672 execution          WARNING  gpt_retrieval_score in line 36 has been running for 60 seconds, stacktrace of thread 3448:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:11:04 -0800   13092 execution          WARNING  gpt_relevance in line 33 has been running for 60 seconds, stacktrace of thread 14408:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:11:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:11:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 32] [Processing: 4] [Pending: 9]
2024-02-26 18:11:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 33 (Process name(SpawnProcess-5)-Process id(13092)-Line number(33)), line 34 (Process name(SpawnProcess-3)-Process id(11968)-Line number(34)), line 35 (Process name(SpawnProcess-4)-Process id(21216)-Line number(35)), line 36 (Process name(SpawnProcess-2)-Process id(26672)-Line number(36)).
2024-02-26 18:11:08 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(33) completed.
2024-02-26 18:11:08 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(37) start execution.
2024-02-26 18:11:17 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(35) completed.
2024-02-26 18:11:17 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(38) start execution.
2024-02-26 18:11:18 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(36) completed.
2024-02-26 18:11:18 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(39) start execution.
2024-02-26 18:11:34 -0800   11968 execution          WARNING  gpt_relevance in line 34 has been running for 60 seconds, stacktrace of thread 20792:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:11:34 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(34) completed.
2024-02-26 18:11:34 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(40) start execution.
2024-02-26 18:11:35 -0800   12436 execution.bulk     INFO     Finished 36 / 45 lines.
2024-02-26 18:11:35 -0800   12436 execution.bulk     INFO     Average execution time for completed lines: 35.85 seconds. Estimated time for incomplete lines: 322.65 seconds.
2024-02-26 18:12:00 -0800   11968 execution          WARNING  [gpt_groundedness in line 40 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 19 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:12:00 -0800   11968 execution          WARNING  [gpt_groundedness in line 40 (index starts from 0)] stderr> RateLimitError #0, Retry-After=19, Back off 19.0 seconds for retry.
2024-02-26 18:12:00 -0800   21216 execution          WARNING  [gpt_retrieval_score in line 38 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:12:00 -0800   21216 execution          WARNING  [gpt_retrieval_score in line 38 (index starts from 0)] stderr> RateLimitError #0, Retry-After=18, Back off 18.0 seconds for retry.
2024-02-26 18:12:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:12:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 36] [Processing: 4] [Pending: 5]
2024-02-26 18:12:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 37 (Process name(SpawnProcess-5)-Process id(13092)-Line number(37)), line 38 (Process name(SpawnProcess-4)-Process id(21216)-Line number(38)), line 39 (Process name(SpawnProcess-2)-Process id(26672)-Line number(39)), line 40 (Process name(SpawnProcess-3)-Process id(11968)-Line number(40)).
2024-02-26 18:12:35 -0800   11968 execution          WARNING  gpt_groundedness in line 40 has been running for 60 seconds, stacktrace of thread 25004:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 991, in _retry_request
    time.sleep(timeout)

2024-02-26 18:12:38 -0800   21216 execution          WARNING  gpt_retrieval_score in line 38 has been running for 60 seconds, stacktrace of thread 27756:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:13:01 -0800   13092 execution          WARNING  [gpt_relevance in line 37 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:13:01 -0800   13092 execution          WARNING  [gpt_relevance in line 37 (index starts from 0)] stderr> RateLimitError #0, Retry-After=18, Back off 18.0 seconds for retry.
2024-02-26 18:13:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:13:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 36] [Processing: 4] [Pending: 5]
2024-02-26 18:13:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 37 (Process name(SpawnProcess-5)-Process id(13092)-Line number(37)), line 38 (Process name(SpawnProcess-4)-Process id(21216)-Line number(38)), line 39 (Process name(SpawnProcess-2)-Process id(26672)-Line number(39)), line 40 (Process name(SpawnProcess-3)-Process id(11968)-Line number(40)).
2024-02-26 18:13:30 -0800   13092 execution          WARNING  gpt_relevance in line 37 has been running for 60 seconds, stacktrace of thread 31008:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 991, in _retry_request
    time.sleep(timeout)

2024-02-26 18:13:36 -0800   26672 execution          WARNING  gpt_relevance in line 39 has been running for 60 seconds, stacktrace of thread 20516:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:13:40 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(39) completed.
2024-02-26 18:13:40 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(41) start execution.
2024-02-26 18:13:53 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(38) completed.
2024-02-26 18:13:53 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(42) start execution.
2024-02-26 18:14:01 -0800   13092 execution          WARNING  [gpt_relevance in line 37 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 19 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:14:01 -0800   13092 execution          WARNING  [gpt_relevance in line 37 (index starts from 0)] stderr> RateLimitError #1, Retry-After=19, Back off 38.0 seconds for retry.
2024-02-26 18:14:01 -0800   26672 execution          WARNING  [gpt_groundedness in line 41 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:14:01 -0800   26672 execution          WARNING  [gpt_groundedness in line 41 (index starts from 0)] stderr> RateLimitError #0, Retry-After=18, Back off 18.0 seconds for retry.
2024-02-26 18:14:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:14:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 38] [Processing: 4] [Pending: 3]
2024-02-26 18:14:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 37 (Process name(SpawnProcess-5)-Process id(13092)-Line number(37)), line 40 (Process name(SpawnProcess-3)-Process id(11968)-Line number(40)), line 41 (Process name(SpawnProcess-2)-Process id(26672)-Line number(41)), line 42 (Process name(SpawnProcess-4)-Process id(21216)-Line number(42)).
2024-02-26 18:14:20 -0800   21216 execution          WARNING  [gpt_groundedness in line 42 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:14:20 -0800   21216 execution          WARNING  [gpt_groundedness in line 42 (index starts from 0)] stderr> RateLimitError #0, Retry-After=29, Back off 29.0 seconds for retry.
2024-02-26 18:14:30 -0800   13092 execution          WARNING  gpt_relevance in line 37 has been running for 120 seconds, stacktrace of thread 31008:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 240, in wrapper
    time.sleep(retry_after_seconds)

2024-02-26 18:14:32 -0800   11968 execution          WARNING  gpt_retrieval_score in line 40 has been running for 60 seconds, stacktrace of thread 25004:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:14:53 -0800   21216 execution          WARNING  gpt_groundedness in line 42 has been running for 60 seconds, stacktrace of thread 31232:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 991, in _retry_request
    time.sleep(timeout)

2024-02-26 18:15:01 -0800   26672 execution          WARNING  [gpt_retrieval_score in line 41 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:15:01 -0800   26672 execution          WARNING  [gpt_retrieval_score in line 41 (index starts from 0)] stderr> RateLimitError #0, Retry-After=18, Back off 18.0 seconds for retry.
2024-02-26 18:15:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:15:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 38] [Processing: 4] [Pending: 3]
2024-02-26 18:15:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 37 (Process name(SpawnProcess-5)-Process id(13092)-Line number(37)), line 40 (Process name(SpawnProcess-3)-Process id(11968)-Line number(40)), line 41 (Process name(SpawnProcess-2)-Process id(26672)-Line number(41)), line 42 (Process name(SpawnProcess-4)-Process id(21216)-Line number(42)).
2024-02-26 18:15:20 -0800   13092 execution          WARNING  [gpt_relevance in line 37 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:15:20 -0800   13092 execution          WARNING  [gpt_relevance in line 37 (index starts from 0)] stderr> RateLimitError #2, Retry-After=29, Back off 116.0 seconds for retry.
2024-02-26 18:15:30 -0800   13092 execution          WARNING  gpt_relevance in line 37 has been running for 180 seconds, stacktrace of thread 31008:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 240, in wrapper
    time.sleep(retry_after_seconds)

2024-02-26 18:15:30 -0800   26672 execution          WARNING  gpt_retrieval_score in line 41 has been running for 60 seconds, stacktrace of thread 29576:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:15:46 -0800   11968 execution          WARNING  gpt_relevance in line 40 has been running for 60 seconds, stacktrace of thread 25004:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:15:54 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(40) completed.
2024-02-26 18:15:54 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(43) start execution.
2024-02-26 18:16:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:16:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 39] [Processing: 4] [Pending: 2]
2024-02-26 18:16:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 37 (Process name(SpawnProcess-5)-Process id(13092)-Line number(37)), line 41 (Process name(SpawnProcess-2)-Process id(26672)-Line number(41)), line 42 (Process name(SpawnProcess-4)-Process id(21216)-Line number(42)), line 43 (Process name(SpawnProcess-3)-Process id(11968)-Line number(43)).
2024-02-26 18:16:17 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(41) completed.
2024-02-26 18:16:17 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(44) start execution.
2024-02-26 18:16:18 -0800   12436 execution.bulk     INFO     Finished 40 / 45 lines.
2024-02-26 18:16:18 -0800   12436 execution.bulk     INFO     Average execution time for completed lines: 39.34 seconds. Estimated time for incomplete lines: 196.7 seconds.
2024-02-26 18:16:20 -0800   21216 execution          WARNING  [gpt_relevance in line 42 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:16:20 -0800   21216 execution          WARNING  [gpt_relevance in line 42 (index starts from 0)] stderr> RateLimitError #0, Retry-After=29, Back off 29.0 seconds for retry.
2024-02-26 18:16:20 -0800   11968 execution          WARNING  [gpt_groundedness in line 43 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:16:20 -0800   11968 execution          WARNING  [gpt_groundedness in line 43 (index starts from 0)] stderr> RateLimitError #0, Retry-After=29, Back off 29.0 seconds for retry.
2024-02-26 18:16:30 -0800   13092 execution          WARNING  gpt_relevance in line 37 has been running for 240 seconds, stacktrace of thread 31008:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 240, in wrapper
    time.sleep(retry_after_seconds)

2024-02-26 18:16:50 -0800   26672 execution          WARNING  [gpt_groundedness in line 44 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 12 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:16:50 -0800   26672 execution          WARNING  [gpt_groundedness in line 44 (index starts from 0)] stderr> RateLimitError #0, Retry-After=12, Back off 12.0 seconds for retry.
2024-02-26 18:16:53 -0800   21216 execution          WARNING  gpt_relevance in line 42 has been running for 60 seconds, stacktrace of thread 31232:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 991, in _retry_request
    time.sleep(timeout)

2024-02-26 18:16:54 -0800   11968 execution          WARNING  gpt_groundedness in line 43 has been running for 60 seconds, stacktrace of thread 4744:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 991, in _retry_request
    time.sleep(timeout)

2024-02-26 18:17:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:17:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 40] [Processing: 4] [Pending: 1]
2024-02-26 18:17:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 37 (Process name(SpawnProcess-5)-Process id(13092)-Line number(37)), line 42 (Process name(SpawnProcess-4)-Process id(21216)-Line number(42)), line 43 (Process name(SpawnProcess-3)-Process id(11968)-Line number(43)), line 44 (Process name(SpawnProcess-2)-Process id(26672)-Line number(44)).
2024-02-26 18:17:17 -0800   26672 execution          WARNING  gpt_groundedness in line 44 has been running for 60 seconds, stacktrace of thread 28396:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 991, in _retry_request
    time.sleep(timeout)

2024-02-26 18:17:21 -0800   11968 execution          WARNING  [gpt_groundedness in line 43 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:17:21 -0800   11968 execution          WARNING  [gpt_groundedness in line 43 (index starts from 0)] stderr> RateLimitError #1, Retry-After=29, Back off 58.0 seconds for retry.
2024-02-26 18:17:30 -0800   13092 execution          WARNING  gpt_relevance in line 37 has been running for 300 seconds, stacktrace of thread 31008:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:17:41 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(37) completed.
2024-02-26 18:17:41 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(45) start execution.
2024-02-26 18:17:53 -0800   21216 execution          WARNING  gpt_relevance in line 42 has been running for 120 seconds, stacktrace of thread 31232:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:17:54 -0800   11968 execution          WARNING  gpt_groundedness in line 43 has been running for 120 seconds, stacktrace of thread 4744:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 240, in wrapper
    time.sleep(retry_after_seconds)

2024-02-26 18:18:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:18:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 41] [Processing: 4] [Pending: 0]
2024-02-26 18:18:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 42 (Process name(SpawnProcess-4)-Process id(21216)-Line number(42)), line 43 (Process name(SpawnProcess-3)-Process id(11968)-Line number(43)), line 44 (Process name(SpawnProcess-2)-Process id(26672)-Line number(44)), line 45 (Process name(SpawnProcess-5)-Process id(13092)-Line number(45)).
2024-02-26 18:18:07 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(21216)-Line number(42) completed.
2024-02-26 18:18:22 -0800   26672 execution          WARNING  [gpt_retrieval_score in line 44 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 28 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:18:22 -0800   26672 execution          WARNING  [gpt_retrieval_score in line 44 (index starts from 0)] stderr> RateLimitError #0, Retry-After=28, Back off 28.0 seconds for retry.
2024-02-26 18:18:51 -0800   13092 execution          WARNING  [gpt_relevance in line 45 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 11 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:18:51 -0800   13092 execution          WARNING  [gpt_relevance in line 45 (index starts from 0)] stderr> RateLimitError #0, Retry-After=11, Back off 11.0 seconds for retry.
2024-02-26 18:19:01 -0800   26672 execution          WARNING  gpt_retrieval_score in line 44 has been running for 60 seconds, stacktrace of thread 28396:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 991, in _retry_request
    time.sleep(timeout)

2024-02-26 18:19:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:19:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 42] [Processing: 3] [Pending: 0]
2024-02-26 18:19:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 43 (Process name(SpawnProcess-3)-Process id(11968)-Line number(43)), line 44 (Process name(SpawnProcess-2)-Process id(26672)-Line number(44)), line 45 (Process name(SpawnProcess-5)-Process id(13092)-Line number(45)).
2024-02-26 18:19:23 -0800   11968 execution          WARNING  [gpt_retrieval_score in line 43 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 28 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:19:23 -0800   11968 execution          WARNING  [gpt_retrieval_score in line 43 (index starts from 0)] stderr> RateLimitError #0, Retry-After=28, Back off 28.0 seconds for retry.
2024-02-26 18:19:23 -0800   26672 execution          WARNING  [gpt_retrieval_score in line 44 (index starts from 0)] stderr> Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 28 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
2024-02-26 18:19:23 -0800   26672 execution          WARNING  [gpt_retrieval_score in line 44 (index starts from 0)] stderr> RateLimitError #1, Retry-After=28, Back off 56.0 seconds for retry.
2024-02-26 18:19:31 -0800   13092 execution          WARNING  gpt_relevance in line 45 has been running for 60 seconds, stacktrace of thread 3200:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:19:50 -0800   11968 execution          WARNING  gpt_retrieval_score in line 43 has been running for 60 seconds, stacktrace of thread 4744:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 240, in wrapper
    time.sleep(retry_after_seconds)

2024-02-26 18:20:01 -0800   26672 execution          WARNING  gpt_retrieval_score in line 44 has been running for 120 seconds, stacktrace of thread 28396:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 240, in wrapper
    time.sleep(retry_after_seconds)

2024-02-26 18:20:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:20:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 42] [Processing: 3] [Pending: 0]
2024-02-26 18:20:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 43 (Process name(SpawnProcess-3)-Process id(11968)-Line number(43)), line 44 (Process name(SpawnProcess-2)-Process id(26672)-Line number(44)), line 45 (Process name(SpawnProcess-5)-Process id(13092)-Line number(45)).
2024-02-26 18:20:05 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(13092)-Line number(45) completed.
2024-02-26 18:21:01 -0800   26672 execution          WARNING  gpt_retrieval_score in line 44 has been running for 180 seconds, stacktrace of thread 28396:
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\common.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\tools\aoai.py", line 153, in chat
    completion = self._client.chat.completions.create(**params)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\promptflow\_core\tracer.py", line 404, in wrapped
    output = func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_utils\_utils.py", line 271, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\resources\chat\completions.py", line 659, in create
    return self._post(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 1180, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 869, in request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 945, in _request
    return self._retry_request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 993, in _retry_request
    return self._request(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\openai\_base_client.py", line 898, in _request
    response = self._client.send(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 915, in send
    response = self._send_handling_auth(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 943, in _send_handling_auth
    response = self._send_handling_redirects(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 980, in _send_handling_redirects
    response = self._send_single_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_client.py", line 1016, in _send_single_request
    response = transport.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpx\_transports\default.py", line 231, in handle_request
    resp = self._pool.handle_request(req)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection_pool.py", line 251, in handle_request
    response = connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 111, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 176, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_sync\http11.py", line 212, in _receive_event
    data = self._network_stream.read(
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1292, in recv
    return self.read(buflen)
  File "c:\Users\anildwa\AppData\Local\miniconda3\envs\code-migration\lib\ssl.py", line 1165, in read
    return self._sslobj.read(len)

2024-02-26 18:21:04 -0800   12436 execution.bulk     INFO     [Process Pool] [Active processes: 4 / 4]
2024-02-26 18:21:04 -0800   12436 execution.bulk     INFO     [Lines] [Finished: 43] [Processing: 2] [Pending: 0]
2024-02-26 18:21:04 -0800   12436 execution.bulk     INFO     Processing Lines: line 43 (Process name(SpawnProcess-3)-Process id(11968)-Line number(43)), line 44 (Process name(SpawnProcess-2)-Process id(26672)-Line number(44)).
2024-02-26 18:21:16 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(11968)-Line number(43) completed.
2024-02-26 18:21:16 -0800   12436 execution.bulk     INFO     Finished 44 / 45 lines.
2024-02-26 18:21:16 -0800   12436 execution.bulk     INFO     Average execution time for completed lines: 42.55 seconds. Estimated time for incomplete lines: 42.55 seconds.
2024-02-26 18:22:00 -0800   12436 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26672)-Line number(44) completed.
2024-02-26 18:22:00 -0800   12436 execution.bulk     INFO     Finished 45 / 45 lines.
2024-02-26 18:22:00 -0800   12436 execution.bulk     INFO     Average execution time for completed lines: 42.58 seconds. Estimated time for incomplete lines: 0.0 seconds.
2024-02-26 18:22:02 -0800   12436 execution.bulk     INFO     Executing aggregation nodes...
2024-02-26 18:22:02 -0800   12436 execution.bulk     INFO     Finish executing aggregation nodes.
