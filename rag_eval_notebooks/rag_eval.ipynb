{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: https://anildwaextopenai3.openai.azure.com/. Model: gpt-35-turbo-1106-ft-38935655ea844c37a954bff664df4358-aml_2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import httpx\n",
    "import openai_setup\n",
    "\n",
    "endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "deployed_model = os.environ[\"DEPLOYMENT_NAME\"]\n",
    "print(f\"Endpoint: {endpoint}. Model: {deployed_model}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "token_provider = get_bearer_token_provider(\n",
    "            DefaultAzureCredential(),\n",
    "            \"https://cognitiveservices.azure.com/.default\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "token_provider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "   api_version=\"2023-03-15-preview\",\n",
    "   azure_deployment=deployed_model,\n",
    "   azure_endpoint=endpoint,\n",
    "   #azure_ad_token_provider=token_provider,\n",
    ")\n",
    "\n",
    "def getOpenAIResp(userQuery, systemMessage, deployed_model='gpt-4-turbo'):\n",
    "    completion = client.chat.completions.create(\n",
    "            model=deployed_model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": systemMessage\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": userQuery\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=4000,\n",
    "            stream=False)\n",
    "    # print(completion.choices[0].message.content)\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot answer this question.\n"
     ]
    }
   ],
   "source": [
    "systemPromptTemplate = \"\"\"\n",
    "You are a machine learning expert agent whose primary goal is to help users with questions with Azure Machine Learning. \n",
    "You are friendly and concise. You only provide factual answers to queries, and do not provide answers that are not related to Azure Machine Learning.\n",
    "Answer based on the context provided to you. If you cannot answer based on the context, say that you cannot answer this question.\n",
    "\n",
    "\"\"\"\n",
    "question = \"tell me a joke\"\n",
    "questionResponse = getOpenAIResp(question, systemPromptTemplate)\n",
    "print(questionResponse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineDocuments(docs, document_separator=\"\\n\\n\"):\n",
    "    # Convert each document in docs to a string in case they are not already.\n",
    "    # This step might be redundant if docs are guaranteed to be strings.\n",
    "    doc_strings = [str(doc) for doc in docs]\n",
    "    \n",
    "    # Use join() method to concatenate doc_strings with document_separator.\n",
    "    combined_document = document_separator.join(doc_strings)\n",
    "    \n",
    "    return combined_document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "chroma_db = Chroma( persist_directory=\"./chroma\",embedding_function=AzureOpenAIEmbeddings(\n",
    "    #azure_ad_token_provider=token_provider,\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"],\n",
    "    azure_endpoint=endpoint,\n",
    "    #http_client=httpx.Client(\n",
    "    # verify=False\n",
    "   #)\n",
    "   ))\n",
    "\n",
    "\n",
    "def getSearchResults(userQuery, numSearchResults=5):\n",
    "    embedding_vector = AzureOpenAIEmbeddings().embed_query(userQuery)\n",
    "    docs = chroma_db.similarity_search_by_vector(embedding_vector, k=numSearchResults)\n",
    "    return combineDocuments(docs[0]), docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "        You only provide factual answers to queries, and do not provide answers that are not related to Azure Machine Learning.\n",
    "        Answer based on the context provided to you. If you cannot answer based on the context, say that you cannot answer this question.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove instruction for FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLLMResponseWithRetriever(userQuery, docs, numSearchResults=5, deployed_model='gpt-4-turbo'):\n",
    "    systemPromptTemplate = \"\"\"\n",
    "        You are a machine learning expert agent whose primary goal is to help users with questions with Azure Machine Learning. \n",
    "        {instruction}\n",
    "        \"\"\"\n",
    "    userMessage = f\"\"\" \n",
    "    <Context>\n",
    "    {docs}\n",
    "    </Context>\n",
    "\n",
    "    <Few_Shot_Example>\n",
    "\n",
    "    UserQuery: {userQuery}\n",
    "    \"\"\"\n",
    "    response = getOpenAIResp(userMessage, systemPromptTemplate, deployed_model)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A compute pool in Databricks is a set of virtual machines that are used to run jobs and interactive clusters. It allows you to manage the resources available to your workloads and can be configured to automatically scale based on demand."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"what is compute pool in databricks?\"\"\"\n",
    "combinedDocs, docs = getSearchResults(question)\n",
    "Markdown(getLLMResponseWithRetriever(query, combinedDocs, deployed_model='gpt-35-turbo-1106-ft-38935655ea844c37a954bff664df4358-aml_2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To integrate Azure Machine Learning with Apache Spark, you can use the AzureML Spark package. This package allows you to submit Spark jobs to an Azure Machine Learning compute target. You can also use the AzureML SDK to create and manage Spark environments and submit Spark jobs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"how to integrate aml with spark?\"\"\"\n",
    "combinedDocs, docs = getSearchResults(question)\n",
    "Markdown(getLLMResponseWithRetriever(query, combinedDocs, deployed_model='gpt-35-turbo-1106-ft-38935655ea844c37a954bff664df4358-aml_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def getResponsePerModel(deployment_name, contextRequired, fileName):\n",
    "    data_path = os.path.join('data')\n",
    "    with open(os.path.join(data_path, fileName), 'w',) as outfile:\n",
    "        with open(os.path.join(data_path, 'aml_questions.txt')) as f:\n",
    "            questions = f.readlines()\n",
    "            questions = [x.strip() for x in questions]\n",
    "            for index, question in enumerate(questions):\n",
    "                print(question)\n",
    "                outfile_format = {\"question\": question, \"variant_id\": \"v1\", \"line_number\":index + 1, \"answer\":\"\",\"context\":[]}\n",
    "                combinedDocs = \"\"\n",
    "                docs = []\n",
    "                if contextRequired:\n",
    "                    combinedDocs, docs = getSearchResults(question)\n",
    "                answer = getLLMResponseWithRetriever(question, combinedDocs,deployed_model=deployment_name)\n",
    "                outfile_format = {\"question\": question, \"variant_id\": \"v1\", \"line_number\":index + 1, \"answer\": answer,\"context\":[str(doc.page_content) for doc in docs]}\n",
    "                json.dump(outfile_format, outfile)\n",
    "                outfile.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do you initiate a new Azure ML experiment using the Azure CLI?\n",
      "Describe the process of creating a new compute instance via the Azure ML CLI. What parameters are necessary?\n",
      "Explain how to submit a training job using Python and the AML SDK v2. Include an example of specifying a compute target.\n",
      "What is the command to list all the models registered in an Azure ML Workspace using the Azure CLI?\n",
      "Provide an example of how to use the AML SDK v2 to stream logs from a running experiment in Python.\n",
      "How can you configure an AutoML run for a classification task using the AML SDK v2, including specifying primary metric and training data?\n",
      "Describe the steps to retrieve the best model from an AutoML run using the AML SDK v2.\n",
      "What are the AutoML capabilities for handling imbalanced data in Azure ML?\n",
      "Explain how to use AutoML for forecasting time series data. What specific settings should be adjusted for time series problems?\n",
      "How do you create a custom deep learning environment with specific Python packages using the AML SDK v2?\n",
      "Describe the process of using Azure ML to train a deep learning model on a GPU compute cluster.\n",
      "Explain how to deploy a TensorFlow model as a web service in Azure ML. What are the key considerations for deployment?\n",
      "Provide an example of how to use the AML SDK v2 for distributed deep learning training. What configurations are necessary for multi-node training?\n",
      "How can Azure ML's HyperDrive be used to tune hyperparameters of a deep learning model? Give an example of specifying the search space.\n",
      "What is the command to update an existing model's properties, such as description or tags, using the Azure CLI?\n",
      "How does Azure ML integrate with Azure DevOps for implementing CI/CD pipelines for ML models? Describe the steps involved.\n",
      "Explain the process of setting up a real-time inferencing endpoint using a deep learning model in Azure ML. What are the performance tuning options available?\n",
      "How can you automate the process of model retraining and deployment using Azure ML Pipelines?\n",
      "Describe the approach to use Azure ML for implementing a recommendation system. What kind of data and algorithms are typically involved?\n",
      "How can you leverage Azure ML's built-in support for ONNX models for interoperability across different frameworks?\n",
      "What Azure storage services can be integrated with Azure Machine Learning for storing datasets?\n",
      "How do you authenticate Azure Machine Learning with Azure Blob Storage to access datasets?\n",
      "What steps are involved in uploading a dataset to Azure Blob Storage and then accessing it from an Azure Machine Learning experiment?\n",
      "Can Azure Machine Learning directly access data stored in Azure Data Lake Storage Gen2? If so, how?\n",
      "How does Azure Machine Learning support versioning of datasets stored in Azure Blob Storage?\n",
      "What is the recommended way to handle large datasets in Azure Machine Learning when the data resides in Azure Blob Storage?\n",
      "How do you use the Azure Machine Learning SDK to programmatically download data from Azure Blob Storage?\n",
      "What are the benefits of integrating Azure Data Lake Storage with Azure Machine Learning for big data scenarios?\n",
      "How can you secure data stored in Azure Storage services when accessed by Azure Machine Learning workspaces?\n",
      "What role do Azure Storage accounts play in deploying Azure Machine Learning models as web services?\n",
      "How do you monitor data access and usage when integrating Azure Machine Learning with Azure Storage?\n",
      "Can Azure Machine Learning use data stored in Azure File Storage? If so, what are the use cases?\n",
      "What are the best practices for managing input and output data for Azure Machine Learning pipelines using Azure Storage?\n",
      "How can you optimize data transfer between Azure Machine Learning and Azure Storage services for efficient model training?\n",
      "What considerations should be taken into account for data privacy and compliance when integrating Azure Machine Learning with Azure Storage?\n",
      "How can you use managed identities to securely access data in Azure Storage from Azure Machine Learning?\n",
      "What are the implications of storage redundancy options in Azure Storage on data availability for Azure Machine Learning experiments?\n",
      "How do you automate the backup and recovery of datasets used in Azure Machine Learning from Azure Storage?\n",
      "What tools and techniques are available for analyzing storage costs associated with Azure Machine Learning projects?\n",
      "How can data engineers streamline the data ingestion process from Azure Storage to Azure Machine Learning for real-time analytics?\n",
      "How can I using MSI with Storage?\n",
      "How can I browse data in the AML workspace?\n",
      "How to use run spark jobs and integrate with ADLS Gen2?\n",
      "How does batch inferencing work in parallel mode?\n",
      "How to deploy custom vision model to real time endpoint?\n",
      "How do you initiate a new Azure ML experiment using the Azure CLI?\n",
      "Describe the process of creating a new compute instance via the Azure ML CLI. What parameters are necessary?\n",
      "Explain how to submit a training job using Python and the AML SDK v2. Include an example of specifying a compute target.\n",
      "What is the command to list all the models registered in an Azure ML Workspace using the Azure CLI?\n",
      "Provide an example of how to use the AML SDK v2 to stream logs from a running experiment in Python.\n",
      "How can you configure an AutoML run for a classification task using the AML SDK v2, including specifying primary metric and training data?\n",
      "Describe the steps to retrieve the best model from an AutoML run using the AML SDK v2.\n",
      "What are the AutoML capabilities for handling imbalanced data in Azure ML?\n",
      "Explain how to use AutoML for forecasting time series data. What specific settings should be adjusted for time series problems?\n",
      "How do you create a custom deep learning environment with specific Python packages using the AML SDK v2?\n",
      "Describe the process of using Azure ML to train a deep learning model on a GPU compute cluster.\n",
      "Explain how to deploy a TensorFlow model as a web service in Azure ML. What are the key considerations for deployment?\n",
      "Provide an example of how to use the AML SDK v2 for distributed deep learning training. What configurations are necessary for multi-node training?\n",
      "How can Azure ML's HyperDrive be used to tune hyperparameters of a deep learning model? Give an example of specifying the search space.\n",
      "What is the command to update an existing model's properties, such as description or tags, using the Azure CLI?\n",
      "How does Azure ML integrate with Azure DevOps for implementing CI/CD pipelines for ML models? Describe the steps involved.\n",
      "Explain the process of setting up a real-time inferencing endpoint using a deep learning model in Azure ML. What are the performance tuning options available?\n",
      "How can you automate the process of model retraining and deployment using Azure ML Pipelines?\n",
      "Describe the approach to use Azure ML for implementing a recommendation system. What kind of data and algorithms are typically involved?\n",
      "How can you leverage Azure ML's built-in support for ONNX models for interoperability across different frameworks?\n",
      "What Azure storage services can be integrated with Azure Machine Learning for storing datasets?\n",
      "How do you authenticate Azure Machine Learning with Azure Blob Storage to access datasets?\n",
      "What steps are involved in uploading a dataset to Azure Blob Storage and then accessing it from an Azure Machine Learning experiment?\n",
      "Can Azure Machine Learning directly access data stored in Azure Data Lake Storage Gen2? If so, how?\n",
      "How does Azure Machine Learning support versioning of datasets stored in Azure Blob Storage?\n",
      "What is the recommended way to handle large datasets in Azure Machine Learning when the data resides in Azure Blob Storage?\n",
      "How do you use the Azure Machine Learning SDK to programmatically download data from Azure Blob Storage?\n",
      "What are the benefits of integrating Azure Data Lake Storage with Azure Machine Learning for big data scenarios?\n",
      "How can you secure data stored in Azure Storage services when accessed by Azure Machine Learning workspaces?\n",
      "What role do Azure Storage accounts play in deploying Azure Machine Learning models as web services?\n",
      "How do you monitor data access and usage when integrating Azure Machine Learning with Azure Storage?\n",
      "Can Azure Machine Learning use data stored in Azure File Storage? If so, what are the use cases?\n",
      "What are the best practices for managing input and output data for Azure Machine Learning pipelines using Azure Storage?\n",
      "How can you optimize data transfer between Azure Machine Learning and Azure Storage services for efficient model training?\n",
      "What considerations should be taken into account for data privacy and compliance when integrating Azure Machine Learning with Azure Storage?\n",
      "How can you use managed identities to securely access data in Azure Storage from Azure Machine Learning?\n",
      "What are the implications of storage redundancy options in Azure Storage on data availability for Azure Machine Learning experiments?\n",
      "How do you automate the backup and recovery of datasets used in Azure Machine Learning from Azure Storage?\n",
      "What tools and techniques are available for analyzing storage costs associated with Azure Machine Learning projects?\n",
      "How can data engineers streamline the data ingestion process from Azure Storage to Azure Machine Learning for real-time analytics?\n",
      "How can I using MSI with Storage?\n",
      "How can I browse data in the AML workspace?\n",
      "How to use run spark jobs and integrate with ADLS Gen2?\n",
      "How does batch inferencing work in parallel mode?\n",
      "How to deploy custom vision model to real time endpoint?\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#getResponsePerModel(\"gpt-4-turbo\", True, \"gpt-4-turbo-aml-results.jsonl\")\n",
    "#getResponsePerModel(\"gpt-35-turbo\", True, \"gpt-35-turbo-aml-results.jsonl\")\n",
    "getResponsePerModel(\"gpt-35-turbo-1106-ft-38935655ea844c37a954bff664df4358-aml_2\", True, \"gpt-35-turbo-ft-aml-results.jsonl\")\n",
    "getResponsePerModel(\"gpt-35-turbo-1106-ft-38935655ea844c37a954bff664df4358-aml_2\", False, \"gpt-35-turbo-ft-nocontext-aml-results.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code-migration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
